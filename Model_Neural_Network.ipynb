{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imammarzuki/publikasi1/blob/main/Model_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myHZuccMUhAT",
        "outputId": "cc44fe34-2d17-4a9f-a882-9945245b8dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 1s 13ms/step - loss: 146.3839 - val_loss: 22.2222\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 12.1097 - val_loss: 3.7400\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4.6204 - val_loss: 3.1972\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3.0032 - val_loss: 2.7658\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.7078 - val_loss: 2.5985\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4928 - val_loss: 2.4742\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 2.4779 - val_loss: 2.4261\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4122 - val_loss: 2.4739\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.4018 - val_loss: 2.3901\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3741 - val_loss: 2.3538\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3727 - val_loss: 2.3347\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3325 - val_loss: 2.3185\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.3404 - val_loss: 2.2910\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.3536 - val_loss: 2.2887\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2781 - val_loss: 2.2524\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2678 - val_loss: 2.2376\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2946 - val_loss: 2.2409\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2516 - val_loss: 2.2015\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2379 - val_loss: 2.2257\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2435 - val_loss: 2.1574\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2085 - val_loss: 2.1599\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.2337 - val_loss: 2.1567\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1894 - val_loss: 2.1658\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.2047 - val_loss: 2.0765\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1302 - val_loss: 2.1334\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0899 - val_loss: 2.0742\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0790 - val_loss: 2.0418\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0691 - val_loss: 1.9941\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.1182 - val_loss: 2.0854\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2.0330 - val_loss: 1.9975\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2.0380 - val_loss: 1.9609\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9773 - val_loss: 1.9212\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9737 - val_loss: 1.9204\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9308 - val_loss: 1.9041\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9188 - val_loss: 2.0487\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9596 - val_loss: 1.8969\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.9458 - val_loss: 1.8606\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9554 - val_loss: 1.8320\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.9089 - val_loss: 1.8463\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8392 - val_loss: 1.8090\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7846 - val_loss: 1.7564\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.7914 - val_loss: 1.7413\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.8115 - val_loss: 1.7097\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7642 - val_loss: 1.7681\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7221 - val_loss: 1.6661\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.7266 - val_loss: 1.6839\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.7115 - val_loss: 1.7636\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.6924 - val_loss: 1.6025\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6940 - val_loss: 1.7725\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6549 - val_loss: 1.7679\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6161 - val_loss: 1.5403\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.6402 - val_loss: 1.6122\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5875 - val_loss: 1.5885\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5685 - val_loss: 1.5313\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.6030 - val_loss: 1.5881\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.4989 - val_loss: 1.4351\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5683 - val_loss: 1.4582\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5760 - val_loss: 1.5929\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.5077 - val_loss: 1.4518\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.5423 - val_loss: 1.3853\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.4735 - val_loss: 1.3577\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.4792 - val_loss: 1.3352\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.4185 - val_loss: 1.3549\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.3829 - val_loss: 1.3709\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.3948 - val_loss: 1.3013\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3522 - val_loss: 1.3960\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3886 - val_loss: 1.2881\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3256 - val_loss: 1.2496\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3440 - val_loss: 1.4439\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.4436 - val_loss: 1.3690\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.4024 - val_loss: 1.2517\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3188 - val_loss: 1.2213\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.2516 - val_loss: 1.1907\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.2644 - val_loss: 1.3226\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.2849 - val_loss: 1.2419\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.2144 - val_loss: 1.1868\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1.2142 - val_loss: 1.1326\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1.3174 - val_loss: 1.1871\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.2549 - val_loss: 1.1150\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.1753 - val_loss: 1.1322\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.1336 - val_loss: 1.4953\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 1.2126 - val_loss: 1.2118\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.1607 - val_loss: 1.0716\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.1605 - val_loss: 1.0590\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.1910 - val_loss: 1.3042\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.2073 - val_loss: 1.0726\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0952 - val_loss: 1.0274\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0765 - val_loss: 1.1090\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.1144 - val_loss: 1.1243\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.1665 - val_loss: 1.1596\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.1428 - val_loss: 1.0616\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.1995 - val_loss: 1.0299\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.2890 - val_loss: 1.0428\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.1623 - val_loss: 1.0465\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 1.0860 - val_loss: 1.0645\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0865 - val_loss: 0.9566\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0848 - val_loss: 0.9923\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0274 - val_loss: 1.0291\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.0390 - val_loss: 1.0202\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 1.1006 - val_loss: 0.9588\n",
            "6/6 [==============================] - 0s 2ms/step\n",
            "MAE on test set: 0.7942128812565523\n",
            "RMSE on test set: 0.9603991715091826\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Misalkan Anda memiliki dataset dalam bentuk DataFrame pandas dengan kolom 'user', 'item', dan 'rating'\n",
        "# Contoh dataset dummy:\n",
        "df= pd.read_csv('eco_rating.csv')\n",
        "\n",
        "# Label encoding untuk kolom 'user' dan 'item'\n",
        "user_encoder = LabelEncoder()\n",
        "item_encoder = LabelEncoder()\n",
        "df['user_id'] = user_encoder.fit_transform(df['user_id'])\n",
        "df['item_id'] = item_encoder.fit_transform(df['item_id'])\n",
        "\n",
        "# Membagi dataset menjadi set pelatihan dan validasi\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Menentukan jumlah pengguna dan item serta ukuran embedding\n",
        "n_users = df['user_id'].nunique()\n",
        "n_items = df['item_id'].nunique()\n",
        "\n",
        "# Model Neural Network (NN)\n",
        "user_input = Input(shape=(1,), name='user_input')\n",
        "item_input = Input(shape=(1,), name='item_input')\n",
        "\n",
        "user_embedding = Dense(64, activation='relu')(user_input)\n",
        "item_embedding = Dense(64, activation='relu')(item_input)\n",
        "\n",
        "merged_vector = Concatenate()([user_embedding, item_embedding])\n",
        "dense_layer = Dense(64, activation='relu')(merged_vector)\n",
        "output_layer_nn = Dense(1, activation='linear', name='output_nn')(dense_layer)\n",
        "\n",
        "nn_model = Model(inputs=[user_input, item_input], outputs=output_layer_nn)\n",
        "nn_model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Melatih model\n",
        "nn_model.fit([train['user_id'], train['item_id']], train['ratings'], batch_size=32, epochs=100, validation_split=0.2)\n",
        "\n",
        "# Memprediksi rating pada set validasi\n",
        "predictions = nn_model.predict([test['user_id'], test['item_id']])\n",
        "\n",
        "# Mengukur kinerja model menggunakan MAE dan RMSE\n",
        "mae = mean_absolute_error(test['ratings'], predictions)\n",
        "rmse = np.sqrt(mean_squared_error(test['ratings'], predictions))\n",
        "\n",
        "print(f'MAE on test set: {mae}')\n",
        "print(f'RMSE on test set: {rmse}')\n"
      ]
    }
  ]
}